\documentclass[12pt,a4paper,twoside,titlepage,openright]{book}
\usepackage[MeX]{polski}
\usepackage[polish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{setspace}
%\singlespacing
\onehalfspacing
\usepackage{enumitem} % słownik pojęć
\usepackage{amsmath}
\usepackage{tabularx} % tabele
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor} % kolory jak~się chce gdzieś użyć
\usepackage{graphicx} % żeby ryciny i~zdjęcia były
\usepackage{listings} % syntax highlighting
\usepackage{verbatimbox} % marginesy dla~tabel
\usepackage{emptypage} % usuwa nagłówki i~numery stron z~pustych stron
\usepackage{afterpage} % to zapobiega ustawianiu obrazka PO tym

\usepackage{multirow}
\usepackage{url}

% PAGE LAYOUT
%\usepackage{showframe} % debug
\marginparwidth 0pt
\marginparsep 0pt
\usepackage[top=2.5cm,bottom=3cm,inner=4.5cm,outer=3cm]{geometry}

% HEADER, FOOTER
\usepackage{fancyhdr} 
\pagestyle{fancy}

% TABLE OF CONTENTS

%kropki w~spisie tresci
\makeatletter
\def\numberline#1{\hb@xt@\@tempdima{#1.\hfil}}
\makeatother

% CHAPTER TITLE

%kropki po~tytułach rodziałów
\makeatletter
\def\@makechapterhead#1{%
  \vspace*{50\p@}%
  {\parindent \z@ \raggedright \normalfont
	\ifnum \c@secnumdepth >\m@ne
	  \if@mainmatter
	   \huge\bfseries \@chapapp\space \thechapter.
	   \par\nobreak
	   \vskip 20\p@
	\fi
   \fi
   \interlinepenalty\@M
   \Huge \bfseries #1\par\nobreak
   \vskip 40\p@
  }}
\makeatother

% TYTUŁY ROZDZIAŁÓW

%kropki po~tytułach rozdziałów
\makeatletter
\renewcommand*\@seccntformat[1]%
{\csname the#1\endcsname.\enspace}
\makeatother


% KONFIGURACJA WYGLĄDU NAGŁÓWKA TEGO CO SIĘ POWTARZA

\fancyhead{} 
\fancyhead[LE]{\rightmark}
\fancyhead[RO]{\leftmark}

% WYGLĄD TABEL

% vertical padding
\renewcommand{\arraystretch}{1.5}

% CODE LISTINGS 

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
%frame=lines,
aboveskip=1.5em,
    belowcaptionskip=1.5em,
    xleftmargin=0.5cm,
  backgroundcolor=\color{white},   % choose the background color
  %basicstyle=\footnotesize,        % size of fonts used for the code
  breaklines=true,                 % automatic line breaking only at whitespace
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  keywordstyle=\color{blue},       % keyword style
  stringstyle=\color{mymauve},     % string literal style
}

\definecolor{maroon}{rgb}{0.5,0,0}
\definecolor{darkgreen}{rgb}{0,0.5,0}

\lstdefinelanguage{XML}
{
  basicstyle=\ttfamily,
  morestring=[s]{"}{"},
  morecomment=[s]{?}{?},
  morecomment=[s]{!--}{--},
  commentstyle=\color{darkgreen},
  moredelim=[s][\color{black}]{>}{<},
  moredelim=[s][\color{red}]{\ }{=},
  stringstyle=\color{blue},
  identifierstyle=\color{maroon},
  morekeywords={Page.DataContext,viewModel:NameViewModel}
}

%\setmonofont{Consolas} %to be used with XeLaTeX or LuaLaTeX
\definecolor{bluekeywords}{rgb}{0,0,1}
\definecolor{greencomments}{rgb}{0,0.5,0}
\definecolor{redstrings}{rgb}{0.64,0.08,0.08}
\definecolor{xmlcomments}{rgb}{0.5,0.5,0.5}
\definecolor{types}{rgb}{0.17,0.57,0.68}

\lstset{language=[Sharp]C,
%captionpos=b,
%numbers=left, %Nummerierung
%numberstyle=\tiny, % kleine Zeilennummern
%frame=lines, % Oberhalb und unterhalb des Listings ist eine Linie
showspaces=false,
showtabs=false,
breaklines=true,
showstringspaces=false,
breakatwhitespace=true,
escapeinside={(*@}{@*)},
commentstyle=\color{greencomments},
morekeywords={partial, var, value, get, set},
keywordstyle=\color{bluekeywords},
stringstyle=\color{redstrings},
basicstyle=\ttfamily\small,
}


% BIBLIOGRAFIA

\usepackage[backend=bibtex8,sorting=none]{biblatex}
\nocite{*}
\addbibresource{bibliography/ccCambridge}
\addbibresource{bibliography/ccBiznes}
\addbibresource{bibliography/cloudFoundry}
\addbibresource{bibliography/kubernetesOreily}
\addbibresource{bibliography/ccSpringer}
\addbibresource{bibliography/azurePackt}
\addbibresource{bibliography/serverlessMaddie}
\addbibresource{bibliography/devOpsPackt}
\addbibresource{bibliography/kubernetesPacktMastering}
\addbibresource{bibliography/kubernetesPacktGettingStarted}
\addbibresource{bibliography/dockerPacktMastering}
\addbibresource{bibliography/microservicesPacktNetCore}
\addbibresource{bibliography/distributedSystems}
\addbibresource{bibliography/soaOreily}
\addbibresource{bibliography/microservicesMaddie}
\addbibresource{bibliography/microservicesWmii}
\addbibresource{bibliography/siteBigTableWikiPl}
\addbibresource{bibliography/siteGoogleBlogCloudSql}
\addbibresource{bibliography/siteGoogleBlogKubernetes}
\addbibresource{bibliography/siteAmazonBlogEks}
\addbibresource{bibliography/siteMicrosoftBlogAks}
\addbibresource{bibliography/siteMicrosoftBlogAzure}
\addbibresource{bibliography/siteAmazonElasticBeanstalkWiki}
\addbibresource{bibliography/siteAmazonRdsWiki}
\addbibresource{bibliography/siteGoogleCloudPlatformWiki}
\addbibresource{bibliography/siteAmazonSimpleDbWiki}
\addbibresource{bibliography/siteOperatingSystemVirtualizationWiki}
\addbibresource{bibliography/siteDockerHistory}
\addbibresource{bibliography/siteCloudControlWiki}
\addbibresource{bibliography/siteUbuntuBlog}
\addbibresource{bibliography/siteDockerStackOverflow}
\addbibresource{bibliography/siteKubernetesBlogBorg}
\addbibresource{bibliography/siteKubernetesOnRaspberry}
\addbibresource{bibliography/siteGoogleTry}
\addbibresource{bibliography/siteAksPricing}
\addbibresource{bibliography/siteAzureTry}
\addbibresource{bibliography/siteAmazonBlogEcs}
\addbibresource{bibliography/siteAmazonEcs}
\addbibresource{bibliography/siteAmazonEcsPricing}
\addbibresource{bibliography/siteAmazonTry}
\addbibresource{bibliography/siteAmazonEksPricing}




\begin{document}

% ################################
%        STRONA TYTUŁOWA
% ################################

\begin{titlepage}

%\newgeometry{inner=3cm,outer=3cm}

\vspace*{1cm}
\begin{center}
\begin{Large}
Uniwersytet Mikołaja Kopernika\\[1mm]
Wydział Matematyki i~Informatyki\\[1mm]
\end{Large}
\end{center}

\vfill

\begin{center}
{\Large Klaudia Augustyńska}\\
nr albumu: 265408\\
informatyka
\end{center}

\vfill

\begin{center}
{\Large Praca magisterska}
\end{center}

\vspace{0.5cm}

\begin{center}
{\Huge \textbf{Wykorzystanie Cloud Computing w aplikacjach mobilnych}}
\end{center}

\vspace{2cm}
\hfill
\begin{minipage}{6.5cm}
Opiekun pracy dyplomowej\\
dr Błażej Zyglarski
\end{minipage}

\vfill

\begin{center}
Toruń 2018
\end{center}

\end{titlepage}

% odwracamy kartkę ze~stroną tytułową to nic nie~ma z~drugiej strony -> pusta strona
\clearpage{\pagestyle{empty}\cleardoublepage}

\tableofcontents
 
\chapter*{Wstęp}
\markboth{}{Wstęp}
\addcontentsline{toc}{chapter}{Wstęp}

Cloud Computing to model stanowiący podstawę dla jednych z najprężniej rozwijających się technologii informatycznych obecnych czasów. Jego wykorzystanie odnosi się do praktycznie wszystkich dziedzin informatyki, poczynając od administrowania infrastrukturą komputerową, przez tworzenie systemów informatycznych, po wsparcie badań naukowych oraz pracy przeciętnych użytkowników komputerów. 

Technologie oparte o Cloud Computing mają swoje podwaliny w starszych technologiach, sięgających lat 70. ubiegłego wieku. Chodzi zatem o produkt ewolucji technologicznej, nie zaś odrębną nową technologię. Dzisiejszy dynamiczny rozwój Cloud Computingu zawdzięczamy m.in. szybkiemu łączu internetowemu, upowszechnieniu komputerów PC oraz mocy obliczeniowej umożliwiającej wirtualizację na poziomie wykorzystania sztucznej inteligencji do inteligentnego zarządzania infrastrukturą komputerową (ang. \textit{autonomic computing}). Złożenie tych czynników umożliwiło urzeczywistnienie idei po raz pierwszy wymienionej w 1961 r. przez Johna McCarthy'ego, który pisał, że zasoby komputerowe staną się użytecznością publiczną -- podobnie jak prąd, który pobieramy z sieci elektrycznej, nie zaś z własnego generatora prądu.\cite{ccCambridge,ccSpringer} Stąd też analizując temat Cloud Computingu niejednokrotnie można spotkać się ze zwrotem ,,X jako usługa" (ang. X \textit{as a service}), ponieważ praktycznie wszystko, co może być związane z wykorzystaniem komputerów, można dostarczać jako usługę. \cite{ccCambridge}

Za chmurami obliczeniowymi stoją olbrzymie centra danych, łączące w sieć nawet tysiące komputerów. Wirtualizacja wykorzystywana w Cloud Computingu pozwala na automatyczną konfigurację nowych serwerów dołączanych do sieci oraz odpowiednie zachowanie sieci w przypadku gdy jakaś jej część przestanie działać. Dzięki takim narzędziom można dowolnie rozbudować sieć, a więc uzyskać dowolną przestrzeń dyskową i moc obliczeniową. Dlatego model chmury obliczeniowej jest nieodzownie powiązany z technikami wirtualizacji oraz technikami pracy na systemach rozproszonych.

Duża i zarazem bardzo znacząca część technologii związanych z Cloud Computingiem dotyczy programowania. Chodzi nie tylko o usługi usprawniające proces wytwórczy oprogramowania, ale również o technologie i wzorce wspierające skalowalność oraz obsługę dużej ilości danych. Chmura pozwala zautomatyzować wiele zadań, z drugiej strony jej ogromne możliwości stanowią duże wyzwanie, gdyż mogą oznaczać całkowitą zmianę podejścia do wytwarzania oprogramowania, wyboru technologii oraz wzorców architektonicznych. Wiele firm powoli podejmuje to wyzwanie przez np. stopniową rezygnację z serwerów firmowych na rzecz serwerów wirtualnych dostępnych w chmurze, wdrażanie strategii CI/CD czy tworzenie nowych projektów w architekturze mikrousług. 

Biorąc pod uwagę w jak szybkim czasie pojawiło się wiele istotnych narzędzi szybko znajdujących zastosowanie w biznesie, istnieje duże zapotrzebowanie na opracowanie tego tematu całościowo. 

\section*{Problem zastosowania chmury obliczeniowej w aplikacjach mobilnych}
\addcontentsline{toc}{section}{Problem zastosowania chmury obliczeniowej w aplikacjach mobilnych}

Chmura obliczeniowa stanowi ważną część tzw. \textit{networked society}, czyli obrazu do którego współcześnie dąży technologia oraz sposób korzystania z niej przez społeczeństwo. Jest to paradygmat w którym korzystanie z elektronicznych asystentów czy IoT (ang. \textit{Internet of Things}) stanowi niezbędny element rzeczywistości.\cite{ccSpringer} W tym nowym obrazie świata chmura stanowi spoiwo, natomiast komunikacja z człowiekiem w dużej mierze odbywa się przy pomocy aplikacji mobilnych. Można spodziewać się rosnącego zapotrzebowania na aplikacje mobilne, których głównym zadaniem jest skuteczna komunikacja z chmurą. 

Podczas wyboru technologii, na etapie analizy dostępnych rozwiązań okazuje się, że istnieje bardzo wiele podejść do tematu, z których duża część powstała w ciągu kilku ostatnich lat i od momentu publikacji zdobyła natychmiastową popularność. Dodatkowo wszystkie materiały, które pozwoliłyby to wszystko zrozumieć, występują w języku angielskim, najczęściej w kontekście wybranego specjalistycznego zastosowania. 

Powyższy problem przyczynia się do braku zrozumienia technologii chmurowych jako całości. Powoduje to niską świadomość jak w pełni wykorzystać możliwości chmury w kontekście tworzenia typowego projektu informatycznego, jakim jest aplikacja mobilna.





\section*{Cel pracy}
\addcontentsline{toc}{section}{Cel pracy}


Celem pracy było rozstrzygnięcie jak na obecny stan wiedzy podejść do problemu realizacji typowego projektu aplikacji mobilnej w oparciu o Cloud Computing. W rozumieniu niniejszej pracy, typowa aplikacja pozwala na wprowadzanie i otrzymywanie danych od serwera za pomocą udostępnionego API. W rezultacie miała zostać wybrana konkretna technologia, która pod względem teoretycznym najlepiej odpowiadałaby stawianym wymaganiom.

Wybrana technologia miała być zastosowana w praktyce do stworzenia aplikacji na system Android, komunikującej się z API udostępnianym przez chmurę. Aplikacja miała umożliwiać zapisywanie wydatków w sposób uwzględniający fakt, że wiele wydatków ludzie dokonują nie tylko z myślą o sobie samych. System miał pozwolić założyć konto w serwisie, a następnie połączyć konta w grupy odpowiadające gospodarstwu domowemu. Kategorie wydatków miały pozwolić na uzgodnienie, kto ile płaci w danej kategorii (np. wydatki na higienę po 50\%). Serwer miał być potrzebny do wspomagania rozliczeń pomiędzy poszczególnymi osobami, dynamicznie naliczając kto ma ile do oddania. Ponadto miał wspomagać kontrolę własnych wydatków przez uwzględnienie, że koszty życia to nie tylko własne wydatki, ale również wydatki poniesione przez inne osoby prowadzące to samo gospodarstwo domowe. Ponieważ tradycyjne programy do zarządzania wydatkami nie posiadają wyżej wymienionych funkcjonalności, jak również zazwyczaj mogą działać bez serwera, to jest przykład aplikacji, która może nagle stać się popularna i powinna być w stanie wówczas obsłużyć większe obciążenie serwera. 



\section*{Opis rozdziałów}
\addcontentsline{toc}{section}{Opis rozdziałów}
\textit{Rozdział 1. -- Wprowadzenie} TODO. NAPISZĘ O TYCH ROZDZIAŁACH W CZASIE PRZESZŁYM, JAk RZECZYWIŚCIE BĘDĄ W CZASIE PRZESZŁYM


\clearpage{\pagestyle{empty}\cleardoublepage}
\chapter{Wprowadzenie}

Niniejszy rozdział wyjaśnia w jaki sposób ewoluowały technologie, by dać się później poznać jako Cloud Computing, a także czego należy oczekiwać od współczesnej chmury. Na końcu rozdziału opisano dokąd zmierza rozwój przedstawionych technologii.



\section{Charakterystyka Cloud Computingu}

Cloud Computing to model zgodnie z którym wszelkie zasoby informatyczne (oprogramowanie, przestrzeń dyskowa, dostęp do bazy danych itp.) dostarczane są w formie usługi. Istotną cechą jest wysoka skalowalność udostępnianych rozwiązań. Po stronie klienta ma to wyglądać tak, jak gdyby posiadał dostęp do nieskończonej mocy obliczeniowej i niekończącej się przestrzeni dyskowej, natomiast po stronie usługodawcy podłączenie nowych serwerów w celu podtrzymania tej iluzji nie powinno stanowić problemu. \cite{ccBiznes}

Aby była możliwa tak wysoka elastyczność, fizyczne serwery są oddzielone warstwą abstrakcji, na której są widoczne jako pula zasobów takich jak przestrzeń dyskowa czy moc procesora. Każdy program czy serwer wirtualny działający w chmurze osadzany jest na wirtualnych zasobach; nie ma możliwości zdecydowania z którego konkretnego fizycznego zasobu chce się korzystać. Moc chmury obliczeniowej buduje się przez łączenie tanich, łatwo wymienialnych komponentów sprzętowych w potężne zasoby wirtualne. \cite{ccCambridge}

Poza rozwiązaniem problemu zarządzania ogromną ilością fizycznych serwerów, wirtualizacja zasobów pozwala na lepsze wykorzystanie sprzętu. W tradycyjnym modelu komputery muszą być przygotowane na wypadek gdyby zainstalowane na nich programy powodowały większe zużycie zasobów. Dzieje się tak nawet w przypadku komputerów PC -- kupuje się specjalnie większe dyski i lepszy procesor, aby przydały się w przyszłości. W ten sposób wykorzystuje się niewielką część możliwości pojedynczego komputera, ponieważ przez większość czasu potrzeba mu znacznie mniej zasobów niż fizycznie posiada. W przypadku wirtualnych zasobów, do fizycznej jednostki można dynamicznie przypisać zużycie powodowane przez wielu użytkowników, wiele wirtualnych systemów operacyjnych, w zgodzie z ustalonym algorytmem. Algorytm może definiować, że np. wszystkie komputery mają zostać obciążone po równo (round robin), czy że pojedynczy węzeł ma być wykorzystany w 100\% \cite{cloudFoundry}. Technikę tę nazywa się równoważeniem obciążenia (ang. \textit{load balancing}).

Technika zrównoważonego obciążenia przynosi kilka ważnych korzyści będących istotnymi cechami chmur obliczeniowych. Dzięki niej usługi działające w chmurze mogą być uruchomione na różnych węzłach, w tylu instancjach, ile wymagane jest do prawidłowego obsłużenia ruchu. W przypadku awarii którejś z instancji użytkownicy usługi niczego nie odczuwają, gdyż zostają przekierowani na instancję co do działania której nie wykazano błędów. Wszystko to ułatwia tworzenie wysoce skalowalnego oprogramowania. Nie bez znaczenia jest także pozytywny wpływ na ekosystem, ponieważ chmury obliczeniowe oznaczają optymalne zużycie istniejącego sprzętu komputerowego, a więc nie trzeba produkować go więcej niż potrzeba ani niepotrzebnie zużywać energii elektrycznej.

Najbardziej spektakularne efekty wykorzystywania modelu chmury widać w przypadku dostawców posiadających największe centra danych na świecie, takich jak Amazon, Microsoft, Google czy IBM. Na kilkudziesięciu $m^{2}$ gromadzą zasoby komputerowe, których równocześnie mogą używać miliony osób na całym świecie. Na jednym fizycznym komputerze zasoby mogą być wykorzystywane przez wiele osób niewiedzących o sobie nawzajem (po angielsku tę właściwość określa się jako \textit{multi-tenancy}). Chmury o takiej architekturze mają potencjał ucieleśnić ideę zgodnie z którą zasoby komputerowe mogą być dostarczane jako usługa użyteczności publicznej.

Wyżej wymieniony sposób myślenia o chmurze jest tym co wyraźnie odróżnia chmury publiczne od chmur prywatnych. Nic nie stoi na przeszkodzie, aby samemu stworzyć prywatną sieć opartą o model chmury. Wówczas formalnie jest to chmura, lecz nie zapewnia niektórych ważnych korzyści, głównie przez konieczność samodzielnego administrowania serwerami, mniejszą ilość potencjalnych użytkowników oraz mniejszy potencjał puli zasobów. Przykładowo, jeśli firma nadal musi martwić się o zarządzanie fizycznymi jednostkami komputerowymi, to nie będzie miała możliwości wychwalać modelu chmury za brak konieczności zatrudniania specjalistów zajmujących się infrastrukturą komputerową.

\subsection*{Korzyści i wady}

Do głównych korzyści wynikających ze stosowania modelu chmury należą:
\begin{itemize}
\item \textbf{rozwiązanie problemu skalowania aplikacji }\\
Wraz z rozwojem Web 2.0, dostępnością szybkiego łącza internetowego, zwiększaniem ilości urządzeń podłączonych do Internetu oraz ilości transmitowanych danych, istnieje rosnące zapotrzebowanie na aplikacje będące w stanie obsłużyć duży ruch. Dzięki chmurom uruchomienie wielu instancji aplikacji na różnych węzłach, dodatkowo w odmiennych wersjach, sprowadza się do opisu - ile, w jakiej wersji, w jakich proporcjach.\cite{kubernetesOreily} Podobnie ułatwione jest korzystanie z baz NoSQL.

\item \textbf{rozwój Big Data} \\
Chmury są w stanie zapewnić odpowiednie środowisko do przechowywania oraz przetwarzania dużych zbiorów danych. Udostępnienie tego środowiska jako usługi znacząco redukuje koszt przechowywania i analizy tych zbiorów, co za tym idzie próg wejścia w ten temat staje się dużo niższy. Za tym idzie wydajniejsze odkrywanie wiedzy z danych, co może mieć wpływ m.in. na rozwój medycyny.

\item \textbf{ochrona środowiska} \\
W modelu chmury sprzęt komputerowy zostaje wydajniej wykorzystany, w związku z tym jest mniejsze zapotrzebowanie na nowy sprzęt. Również dzięki pozostawieniu kosztownych operacji po stronie chmury, urządzenia klienckie łączące się z chmurą nie muszą być regularnie wymieniane na silniejsze.

\item \textbf{lepsza koncentracja na wybranym zadaniu} \\
Model chmury zwalnia użytkowników z dodatkowych czynności przy realizacji danego zadania. Przykładowo, jeśli komuś jest potrzebny serwer, to z chmurą publiczną nie musi martwić się zakupem sprzętu, zapewnieniem odpowiedniego pomieszczenia czy dostępem do Internetu. Może się zamiast tego skupić na właściwym skonfigurowaniu systemu na serwerze wirtualnym. 

\item \textbf{płatność tylko za rzeczywiste zużycie} \\
Chmura umożliwia rozliczanie na podstawie czasu używania procesora, ilości przesłanych megabajtów czy ilości danych przechowywanych w chmurze. W szczególności zmniejsza to początkowy koszt wdrażania czegokolwiek w chmurze.

\item \textbf{gwarancja jakości usługi} \\
Każdy dostawca usług chmurowych udostępnia klientom SLA (ang. \textit{Service-level aggrements}), w którym zobowiązuje się do utrzymania określonego poziomu niezawodności usług (np. dostępność w 99,9\% przypadków) oraz przewidywanego zachowania w przypadku niedotrzymania zapewnień (np. obniżki cen).

\end{itemize}

Ostatnią korzyścią, a jednocześnie kontrowersją, jest bezpieczeństwo danych w chmurach publicznych. Wysyłanie niejednokrotnie wrażliwych danych w nie do końca określone miejsce budzi obawy. Według autorów specjalistycznych wydawnictw\cite{ccCambridge,ccBiznes} są niesłuszne -- pozostają zgodni co do opinii, że główni dostawcy usług chmurowych są w stanie zapewnić najwyższy poziom bezpieczeństwa, a fizyczne przechowywanie danych na terenie firmy daje tylko ułudę bezpieczeństwa.

Do potencjalnych wad rozwiązań bazujących na chmurach obliczeniowych należą:

\begin{itemize}

\item \textbf{problem z przenoszeniem aplikacji z jednej chmury na drugą}

Znaczna część usług oferowanych przez największych dostawców usług chmurowych jest dedykowana dla tworzonej przez nich chmury. Oznacza to, że jeśli użytkownik chce mieć możliwość zmiany dostawcy, powinien uwzględnić to przy wyborze narzędzi pracy. Więcej na ten temat można przeczytać w rozdziale 3.

\item \textbf{problemy prawne}

Istnieje ryzyko rozbieżności pomiędzy prawem do którego dostosowywał się dostawca usług chmurowych, a prawem chroniącym dane w kraju, na terenie którego chce się korzystać z tych usług. 

\end{itemize}


\section{Ewolucja Cloud Computingu}

Cloud Computing nie stanowi odrębnej, nowej technologii -- jest to produkt ewolucji technologii rozwijanych od blisko 50 lat. Prześledzenie historii pozwala na zrozumienie, które koncepcje rzeczywiście wprowadzają nową jakość, a nie są jedynie od dawna istniejącą technologią, tyle że  ubraną w ładnie brzmiące słowo.

\subsection{Historia technologii chmurowych}

Historia ma początek około lat 70., gdy używano wielkich superkomputerów zwanych \textbf{\textit{mainframe}}. Można było z nich korzystać za pomocą terminali, określanych mianem ,,głupich'' (ang. \textit{dump terminal}), ponieważ nie posiadały procesora i mogły być używane jedynie do operacji I/O. Jako że z serwera mógł korzystać jeden terminal naraz, serwer ustawiał je w kolejkę i musiały długo czekać na obsłużenie.

W latach 70. terminale zaczęły być wyposażone w mikroprocesory i być określane mianem \textbf{,,inteligentnych terminali''} (ang. \textit{inteligent terminal}). Mogły już partycypować przy uruchamianiu programów, co skróciło czas obsługi i dało początek modelowi klient-serwer.

Dalszy rozwój umożliwił rozwój mikroprocesorów, co dało początek \textbf{komputerom PC}. Komputery te mogły działać samodzielnie i były znacznie tańsze od mainframe-a.

Wynaleziono również LAN (ang. \textit{local area network}) i WAN (ang. \textit{wide area network}), co umożliwiło łączenie komputerów PC w sieci bez konieczności łączenia z mainframe-m. Powstały sieci \textbf{P2P} (ang. \textit{Peer-To-Peer}).

We wczesnych latach 80. wynaleziono \textbf{systemy rozproszone}. Ponieważ były w stanie przetwarzać dane równolegle, zachwiało to poglądem iż większą moc obliczeniową należy uzyskiwać przez wynajdowanie silniejszych procesorów. Systemy rozproszone wymagały wzmożonej ilości operacji komunikacji, lecz występowało to w parze z rozwojem LAN osiągającym przepustowość 100 Mbps oraz WAN osiągającym 64 kbps.

Następnie powstała koncepcja \textbf{klastrów komputerowych}. Klaster polegał na połączeniu komputerów tego samego typu (homogenicznych) w sieć LAN i wyłonieniu wśród nich zarządcy, który będzie zajmował się przydzielaniem zadań pozostałym węzłom. Gdyby któryś z węzłów miał awarię, to inne mogły przejąć jego zadanie. Dało to początek idei \textbf{puli zasobów}. W klastrze niezawodność osiągało się przez nadmiarowość zasobów.

Główną wadą klastrów była konieczność powierzenia zarządzania klastrem jednemu komputerowi. Stanowił on miejsce od niezawodności którego zależała niezawodność całej sieci (ang. \textit{single point of failure}). Rozwiązaniem okazały się \textbf{gridy}, w których każdy węzeł posiadał równy priorytet. Klient mógł podłączyć się do dowolnego komputera w gridzie, a ponadto komputery te mogły być różnego typu (heterogeniczne). Wkrótce gridy przeniknęły ze świata naukowego do świata biznesu i zaczynały być łączone przez WAN.

Dotychczas gdy uruchamiało się program na wybranym węźle gridu, to znajdował się na tym węźle dopóki proces nie został zakończony. Stanowiło to problem na drodze do skalowania w czasie rzeczywistym, gdzie na skutek zmienionych potrzeb byłoby dobrze mieć możliwość od nowa zaalokować zasoby bez zakłócania działającej usługi. Problem ten rozwiązała \textbf{wirtualizacja sprzętowa}, za pomocą której zadania były alokowane do maszyn wirtualnych. Technika ta umożliwiła \textbf{utility computing}, czyli model w którym zasoby komputerowe mogą być dostarczane jako usługa, co stanowi serce chmur obliczeniowych. Prekursorem została firma Salesforce.com, która udostępnia oprogramowanie w formie usługi internetowej od 1999 r.


W 2001 r. firma IBM zbudowała pierwszy \textbf{autonomiczny system} (ang. \textit{antonomic computing}) -- system, który potrafi sobą zarządzać bez interwencji człowieka. Dzięki wykorzystaniu sztucznej inteligencji do działania, eliminuje się ryzyko związane z błędem ludzkim oraz złożoność związaną z koniecznością doglądania przez człowieka złożonego systemu. IBM wytyczył następujące cechy modelu:
\begin{itemize}
\item automatyczna konfiguracja -- konfiguracja tworzy się automatycznie na podstawie zapotrzebowania,
\item automatyczna naprawa błędów -- system sam wykrywa błędy i reaguje na nie,
\item automatyczna optymalizacja -- system sam dba o optymalne użycie zasobów,
\item automatyczna ochrona -- system wykrywa próby ataków i zapobiega im.
\end{itemize}
Wirtualizacje w tym systemie działają zgodnie z ,,pętlą adaptacyjną'': obserwuj, decyduj, zareaguj.\cite{ccSpringer}


Duże znaczenie miało także wynalezienie metody \textbf{SOA} (ang. service oriented architecture), czyli techniki wytwarzania oprogramowania przez wydzielanie niezależnie działających komponentów, składających się razem na większy system informatyczny. Ważna była również koncepcja \textbf{Web 2.0}, nazwana tak po raz pierwszy w 2002 r. roku. Model Web 2.0 spowodował zmiany w sposobie myślenia o Internecie, zgodnie z którymi nie powinien jedynie służyć do dostarczania statycznej treści, lecz może być użyteczny również do udostępniania treści tworzonej przez użytkowników Internetu.

Wymienione wyżej technologie zestawione razem dały podwaliny chmurom obliczeniowym.

Przyjmuje się, że termin \textit{,,cloud computing''} po raz pierwszy został użyty przez CEO firmy Google, Erica Schmidta, w trakcie konferencji w 2006 r. Tego samego roku Amazon użył tej nazwy publikując pionierską w swoim gatunku usługę Elastic Compute Cloud (EC2), czyli możliwość wynajmu serwera wirtualnego w ich chmurze.

\subsection{Historia najnowsza. Współczesne wyzwania}

Odkąd Amazon uruchomił usługę EC2, nastąpił gwałtowny rozwój rozwiązań chmurowych. Praktycznie w tym samym czasie rozwinęły się technologie postrzegane w czasie pisania niniejszej pracy jako rewolucyjne. Na potrzeby opracowania wyróżniono następujące grupy zmian:
\begin{itemize}
\item rozwój chmur publicznych,
\item rozwój rozwiązań opartych o kontenery,
\item rozwój technik programistycznych wyznaczających najlepsze praktyki tworzenia aplikacji dla chmury.
\end{itemize}

\subsubsection*{Rozwój chmur publicznych}

W 2003 roku firma Citrix stworzyła Xen - system operacyjny przeznaczony tylko do wirtualizacji innych systemów operacyjnych. Niedługo potem Xen został udostępniony jako oprogramowanie otwartoźródłowe. W marcu 2006 r. roku Amazon na podstawie Xena opracował swój produkt EC2. W ciągu 18 miesięcy zaczęło z niego korzystać ponad pół miliona osób.\cite{ccBiznes}

W kolejnych latach powstały kolejne chmury publiczne oraz nastąpił rozwój rozwiązań typu PaaS (ang. \textit{platform as a service}). W czerwcu 2007 r. powstał Heroku, będący pionierem w tej kategorii. Niecały rok później Google udostępnił usługę Google App Engine. W lutym 2010 r. Microsoft udostępnił Windows Azure (w kwietniu 2014 przemianowaną na Microsoft Azure \cite{azurePackt}).

Do tego momentu powstały już 3 największe chmury publiczne: Amazon AWS, Google Cloud Platform, Microsoft Azure. Początkowo miały zróżnicowaną ofertę. W literaturze\cite{ccBiznes} z 2011 r. porównywanie tych platform sprowadzało się do zakresu oferowanych przez nie usług. Z biegiem czasu różnice zatarły się -- obecnie usługa publikowana przez jednego dostawcę po kilku miesiącach jest dostępna także u innych. Tabela \ref{table:historia} prezentuje porównanie tempa rozbudowy zakresu usług.

\noindent
\begin{small}
\begin{table}[t]
\newcolumntype{L}{>{\raggedright\arraybackslash}X}%
\begin{tabularx}{\textwidth}{ |L|L|L|L| }

\hline
\multirow{2}{*}{Typ usługi} & \multicolumn{3}{|c|}{Dostawca} \\

\cline{2-4}
& \multicolumn{1}{|c|}{AWS} & \multicolumn{1}{|c|}{GCP} & \multicolumn{1}{|c|}{Azure} \\

\hline
serwery wirtualne & 2006 -- Amazon EC2 \cite{ccCambridge} & 2013 -- Google Compute Engine \cite{siteGoogleCloudPlatformWiki} & 2010 -- 	Azure Virtual Machines \cite{siteMicrosoftBlogAzure} \\

\hline
platforma aplikacji & 2011 -- AWS Elastic Beanstalk \cite{siteAmazonElasticBeanstalkWiki} &  2008 -- Google App Engine \cite{siteGoogleCloudPlatformWiki} & 2010 -- Azure Cloud Services \cite{siteMicrosoftBlogAzure} \\

\hline
bazy SQL & 2009 -- Amazon Relational Database Service \cite{siteAmazonRdsWiki} & 2011 -- Google Cloud SQL \cite{siteGoogleBlogCloudSql} & 2010 -- Azure SQL Database \cite{siteMicrosoftBlogAzure} \\

\hline
bazy klucz-wartość & 2007 -- Amazon SimpleDb (w 2012 Amazon DynamoDB) \cite{siteAmazonSimpleDbWiki} & 2008 -- Google Bigtable \cite{siteBigTableWikiPl} (jako część App Engine) & 2010 -- Azure Table Storage \cite{siteMicrosoftBlogAzure} (2017 -- Azure Cosmos DB) \\

\hline
serverless & 2014 -- AWS Lambda \cite{serverlessMaddie} & 2016 -- Google Cloud Functions \cite{serverlessMaddie} & 2016 -- Azure Functions \cite{serverlessMaddie}\\

\hline
Kubernetes & 2018 -- Amazon Elastic Container Service for Kubernetes \cite{siteAmazonBlogEks} & 2015 -- Google Kubernetes Engine \cite{siteGoogleBlogKubernetes}  & 2017 -- Azure Container Service \cite{siteMicrosoftBlogAks}\\

\hline



\end{tabularx}


\caption{Porównanie historii udostępniania usług chmurowych wśród głównych dostawców}
		\label{table:historia}

\end{table}
\end{small}

\subsubsection{Konteneryzacja i DevOps}

W tym samym czasie rozwijały się technologie przeznaczone do wystawiania własnych usług chmurowych. W 2010 r. powstała otwartoźródłowa platforma \textbf{OpenStack} służąca do świadczenia własnych usług typu IaaS. Rok później powstał \textbf{Cloud Foundry} -- również otwartoźródłowy projekt, pozwalający na prowadzenie własnej platformy typu PaaS do tworzenia aplikacji w chmurze. 

Cloud Foundry stanowił odpowiedź na główny problem chmur publicznych -- tworzenie aplikacji na wybraną chmurę wiązało ją z mechanizmami specyficznymi dla tej chmury. Brakowało pomostu, który oddzieliłby warstwę tworzenia aplikacji w chmurze od wybranego usługodawcy, bez konieczności tworzenia serwerów wirtualnych na których trzeba instalować określone środowisko. \cite{cloudFoundry}

Cloud Foundry jest niezależny od infrastruktury, może działać zarówno na OpenStacku jak i na serwerze wirtualnym w chmurze publicznej. Zapewnia możliwość wyboru dowolnych technologii do wytwarzania oprogramowania. Do działania używa kontenerów zgodnych ze standardem OCI (Open Container Initiative). \cite{cloudFoundry} 

\textbf{Konteneryzacja} to metoda wirtualizacji na poziomie systemu operacyjnego, gdzie na działającym systemie operacyjnym można uruchomić wiele odizolowanych od siebie instancji przestrzeni użytkownika. Każda taka instancja to kontener. Kontener zapewnia odpowiednie środowisko do działania dla umieszczonej w nim aplikacji, np. środowisko uruchomieniowe .NET Core w odpowiedniej wersji.  \cite{cloudFoundry,ccSpringer}

Cloud Foundry zapewnia orkiestrację kontenerów oraz obsługę procesu CI/CD (ciągłej integracji i ciągłego dostarczania, ang. \textit{continuous integration / continuous delivery}).\cite{cloudFoundry} Stanowi narzędzie pozwalające z powodzeniem wdrażać strategie DevOps. 

\textbf{DevOps} to słowo po raz pierwszy użyte 2009 r. na konferencji w Belgii. Stanowi połączenie ze sobą słów \textit{,,development''} (rozwój) i \textit{,,operations''} (eksploatacja). Wskazuje to na zacieśnianie współpracy pomiędzy zespołami zajmującymi się rozwojem oprogramowania, a zespołami, które je wdrażają. Współpraca ta ma doprowadzać do automatyzacji procesów towarzyszących wytwarzaniu oprogramowania, co w efekcie minimalizuje czas potrzebny od wprowadzenia poprawki do wdrożenia na środowisko produkcyjne, zachowując przy tym niezawodność. Jako strategie DevOps określa się wszelkie technologie i narzędzia inżynierii oprogramowania, które dają taki efekt. \cite{devOpsPackt}

Temat DevOps jest mocno powiązany z chmurami, ponieważ jego koncepcje znacząco redukują złożoność towarzyszącą tworzeniu wysoce skalowalnego oprogramowania. Jednocześnie wychodzą one naprzeciw wymaganiom społeczeństwa coraz bardziej przyzwyczajonego do częstych aktualizacji oprogramowania, szybkiej reakcji na błędy oraz braku przestojów towarzyszących wdrażaniu nowych wersji. W przypadku chmur obliczeniowych, w których jedna usługa internetowa może mieć np. kilkadziesiąt instancji na różnych węzłach, taka automatyzacja ma kluczowe znaczenie. W związku z tym pojęcie DevOps obecnie wchodzi w kanon pojęć związanych z chmurą.

Istotny element DevOps stanowią wcześniej wspomniane kontenery. Idea kontenerów kiełkowała już kilka lat wcześniej, np. Solaris Containers z 2004 r. lub OpenVZ (2005 r.) i LXC (Linux Containers -- 2008 r.), które w istocie do działania wykorzystywały UNIX-owy program chroot z 1982 r.\cite{siteOperatingSystemVirtualizationWiki} Jednak prawdziwe ożywienie spowodowało dopiero pojawienie się Dockera -- sprawił iż tworzenie kontenerów oraz przenoszenie ich pomiędzy systemami stało się łatwe. Na nim bazuje kilka projektów intensywnie rozwijanych w czasie pisania niniejszej pracy.

\textbf{Docker} to system kontenerów, który powstał jako element platformy dotCloud, świadczącej usługi typu PaaS. Spopularyzował się w dość osobliwy sposób. Założyciel myślał, że tylko wygłosi mały referat na PyCon w 2013 r., lecz okazało się, że na konferencji było dużo osób, a jego referat był głównym elementem programu. Do końca roku Docker miał 100 mln pobrań, 3 miesiące później -- 300 mln, a w czerwcu 2017 -- 13 miliardów.\cite{siteDockerHistory} Z kolei platforma dotCloud nie okazała się sukcesem -- w 2014 r. Docker Inc. sprzedał ją niemieckiej firmie cloudControl GmbH, która w grudniu 2015 r. zbankrutowała, a w marcu 2016 r. zamknęła usługę.\cite{siteCloudControlWiki}

Logo Dockera dobrze opisuje jego istotę. Przedstawia wieloryba transportującego kontenery. Miało to nawiązywać do tego, iż załadowanie statku trwa dłużej niż transport statkiem. Ma to swoją alegorię do programowania. W tradycyjnym podejściu, gdyby zechcieć uruchomić np. aplikację napisaną w ASP.NET, najpierw trzeba byłoby poświęcić kilka godzin na pobieranie i instalację narzędzi: Visual Studio z narzędziami sieci Web, serwer IIS oraz SQL Server LocalDB. Natomiast w podejściu Dockera byłoby to:
\begin{enumerate}
\item napisanie pliku Dockerfile z definicją zależności: system Windows, MSBuild, .NET Framework, serwer IIS, menadżer pakietów NuGET,
\item użycie CLI Dockera oraz pliku Dockerfile do zbudowania tzw. obrazu Dockera,
\item użycie obrazu Dockera do zbudowania i uruchomienia aplikacji w kontenerze.
\end{enumerate}
Obrazy Dockera działają wszędzie, gdzie jest zainstalowany Docker -- niezależnie od systemu operacyjnego czy środowisk jakie ma zainstalowane. Ponadto zależności takie jak np. system operacyjny Ubuntu występują w wersjach ,,odchudzonych'' - przykładowo obraz Minimal Ubuntu 18.04 zajmuje jedynie 29 MB.\cite{siteUbuntuBlog}. Najlżejszym obrazem Linuxa jest dystrybucja Alpine wielkości niecałych 4 MB, stąd używana jest jako baza dla obrazów zapewnianych przez Docker.\cite{dockerPacktMastering}
Podejście Dockera stwarza następujące możliwości:
\begin{itemize}
\item Na jednej maszynie może jednocześnie działać wiele aplikacji wymagających różnych zależności, lub nawet różniących się jedynie wersjami, w izolacji od siebie oraz maszyny na której są uruchomione.
\item W procesie wytwarzania oprogramowania gwarantuje użycie identycznych wersji zależności na środowisku deweloperskim, testowym oraz produkcyjnym. Eliminuje to problem gdy na zgłoszony błąd słyszy się odpowiedź ,,u mnie działa''.
\item Obrazy Dockera są lekkie: współdzielą wiele zasobów systemu operacyjnego, dzielą między sobą inne obrazy Dockera.\cite{siteDockerStackOverflow} Na jednej maszynie może działać wiele kontenerów Dockera, podczas gdy maszyn wirtualnych może być zaledwie kilka.\cite{ccSpringer}
\end{itemize}
Powyższe znacząco ułatwia tworzenie aplikacji ,,dla chmury'', orkiestrację chmury oraz stosowanie strategii DevOps.

W 2014 r. Google udostępnił system \textbf{Kubernetes}, służący do orkiestracji kontenerów w chmurze. Wywodzi się z projektu Borg, będącego wewnętrznym narzędziem Google do obsługi 2 miliardów\cite{kubernetesPacktGettingStarted} kontenerów tygodniowo, dopracowywanym w tej firmie od ponad dekady.\cite{siteKubernetesBlogBorg} Jako główny system kontenerów wykorzystuje Dockera.\cite{kubernetesOreily} Może zostać skonfigurowany zarówno na fizycznych serwerach jak i na serwerach wirtualnych (można też je mieszać).\cite{kubernetesPacktMastering}

Na pierwszy rzut oka Kubernetes przypomina Cloud Foundry, jest to jednak zupełnie inne narzędzie. Tabela \ref{table:kubernetes} prezentuje porównanie tych dwóch platform.


\noindent
\begin{small}
\begin{table}[h]
\newcolumntype{L}{>{\raggedright\arraybackslash}X}%
\begin{tabularx}{\textwidth}{ |L|L| }

\hline
Cloud Foundry & Kubernetes \\
\hline
powstał w 2011 r. & powstał w 2014. r. \\
\hline
wysoki poziom automatyzacji -- rozpoznaje zależności aplikacji, sam buduje kontener i konfiguruje skalowanie aplikacji & więcej kontroli nad kontenerami, lecz także więcej pracy dla deweloperów. Dla większej automatyzacji należy sięgnąć po rozwiązania PaaS bazujące na Kubernetes, takie jak RedHat OpenShift \cite{kubernetesPacktGettingStarted} \\
\hline
minimalne wymagania -- 40 GB HDD, 8 GB RAM, 4 rdzenie CPU & 2 GB RAM, 2 rdzenie CPU. Na tyle lekki, że można go używać na Raspberry PI \cite{siteKubernetesOnRaspberry} \\
\hline
domyślnie używa własnego systemu kontenerów, ale pozwala na korzystanie z obrazów Dockera & stosuje obrazy Dockera jako główny system kontenerów, ale pozwala zastąpić go innym \\
\hline


\end{tabularx}


\caption{Główne różnice pomiędzy Cloud Foundry i Kubernetes}
		\label{table:kubernetes}

\end{table}
\end{small}

Do tego momentu kontenery jawią się jako antidotum na przywiązanie do wybranego dostawcy usług chmurowych. Aplikacje w kontenerze Dockera mogą używać szerokiego wachlarza technologii, nie tylko otwartoźródłowych jak np. MongoDB, Node.js, .NET Core. Jako zależność można podać np. OpenJDK czy obraz systemu Windows Server udostępniany przez Microsoft, następnie można do niego doinstalować inne zależności komendą \texttt{RUN} w Dockerfile. \cite{dockerPacktMastering} Dostępność platformy Kubernetes wyznaczyła standard w zarządzaniu kontenerami na szeroką skalę.

Problemem, który w wielu przypadkach mógł podnosić barierę wejścia do stosowania takich rozwiązań, była konieczność samodzielnej instalacji Kubernetes lub podobnego narzędzia na serwerze wirtualnym w chmurze. Chmury publiczne wyszły naprzeciw tym oczekiwaniom i zaczęły udostępniać usługi typu \textbf{CaaS} (ang. \textit{Containers-as-a-Service}), nazywane też KaaS (ang. \textit{Kubernetes-as-a-Service}). Jako przykłady można wymienić:
\begin{itemize}
\item \textbf{Google Kubernetes Engine} (wcześniej: Google Container Engine) -- usługa udostępniona w sierpniu 2015 r. \cite{siteGoogleBlogKubernetes} z gotowym do użycia Kubernetes. Można ją przetestować za darmo w ramach kredytu 300 USD do testowania Cloud Platform.\cite{siteGoogleTry}
\item \textbf{AKS -- Azure Kubernetes Service} (wcześniej: Azure Container Service) -- początkowo od 2015 r. wspierała orkiestratory Mesosphere DC/OS oraz Docker Swarm, jednak na fali popularności Kubernetes firma Microsoft uznała go za standard i w 2017 r. opracowała wsparcie dla Kubernetes. W związku z tym nastąpiła także zmiana nazwy usługi. \cite{siteMicrosoftBlogAks} Usługa jest darmowa\cite{siteAksPricing}, opłaty są naliczane za użyte maszyny wirtualne, które przez rok również w ograniczonym zakresie są bezpłatne.\cite{siteAzureTry}
\item \textbf{Amazon ECS -- Amazon Elastic Container Service} -- usługa dostępna od kwietnia 2015 r., jest to własna implementacja orkiestracji kontenerów Dockera stworzona przez Amazona. Pozwala na 2 typy rozliczeń: płatność za zużycie zasobów przez kontener lub płatność za przechowanie i uruchamianie aplikacji na EC2.\cite{siteAmazonEcsPricing} Nie występuje na liście usług dostępnych do wyprówowania za darmo.\cite{siteAmazonTry}
\item \textbf{Amazon EKS -- Amazon Elastic Container Service for Kubernetes} -- usługa została uruchomiona w czerwcu 2018 r. Publikując usługę Amazon chwalił się, że na podstawie danych Cloud Native Computing Foundation (założonej wraz z powstaniem Kubernetes), 57\% firm korzystających z Kubernetes robiło to na serwerach wirtualnych AWS. Płatność wynosi 0.20 USD za godzinę dla każdego klastra w usłudze a dodatkowo za zużycie zasobów AWS.\cite{siteAmazonEksPricing} Nie występuje na liście usług dostępnych do wyprówowania za darmo.\cite{siteAmazonTry}
\end{itemize}

Dostępność tych usług ucieleśnia wizję tworzenia aplikacji dla chmury tak że:
\begin{itemize}
\item Do tworzenia aplikacji można wybrać dowolną technologię i wciąż koncentrować się na tworzeniu tej aplikacji, a nie zapewnianiu jej odpowiedniego środowiska na serwerze wirtualnym.
\item Istnieje standardowy sposób tworzenia obrazu kontenera (Docker).
\item Istnieje standardowy sposób orkiestracji kontenerów (Kubernetes). Wiedzę na temat korzystania z niego można zastosować do projektów działających na chmurach publicznych, prywatnych i hybrydowych.
\end{itemize}

\subsubsection*{Aplikacje cloud native}

Gwałtowny rozwój chmur obliczeniowych poskutkował również wytworzeniem nowych wzorców projektowych, wzorców architektonicznych oraz dobrych praktyk używanych podczas tworzenia aplikacji przeznaczonej dla chmury. W chmurze może działać praktycznie każdy program, wszakże odpowiednio przygotowana maszyna wirtualna wszystko przyjmie. Chcąc jednak maksymalnie wykorzystać atuty chmury, a jednocześnie zapewnić niezawodność i jak najniższy koszt eksploatacji, należy zapoznać się ze specyficznym sposobem tworzenia aplikacji dla chmury. Aplikację zgodną z tymi wytycznymi określa się jako \textbf{\textit{cloud native}}.

Jak zostało wspomniane wcześniej, platforma Heroku była pionierem jeśli chodzi o udostępnianie programistom platformy do tworzenia aplikacji w chmurze (2007 r.). Współzałożyciel Heroku, Adam Wiggins wraz z zespołem, w 2012 r. na podstawie doświadczeń zebranych w Heroku stworzyli metodykę ,,twelve-factor'' (ang. \textbf{\textit{The Twelve-Factor App}}). Jest to zbiór podstawowych 12. reguł dotyczących programowania oraz pracy z aplikacjami przeznaczonymi dla chmury. Reguły te są często przywoływane w literaturze zajmującej się tym tematem.\cite{cloudFoundry, microservicesPacktNetCore} Można się z nimi zapoznać odwiedzając stronę \texttt{https://12factor.net} (w czasie pisania pracy strona była dostępna w 13 językach, w tym w języku polskim).

Osobne ,,dobre praktyki'' powstały dla systemów rozproszonych używających kontenerów (w tym Kubernetes). Dzielą się na:
\begin{itemize}
\item Wzorce dla kontenerów występujących na jednym węźle (ang. \textit{Single-node patterns}. Należą do nich wzorce: \textit{Sidecar, Ambassador, Adapter}.
\item Wzorce dla kontenerów występujących na różnych węzłach (ang. \textit{Multi-node patterns}). Koncentrują się na właściwych metodach koordynacji działań pomiędzy różnymi maszynami. Są to wzorce np. komunikacji z użyciem zdarzeń czy kolejek.  \cite{kubernetesPacktMastering, distributedSystems}
\end{itemize}

Praktyki wyznaczone przez powyższe wzorce w dużej mierze opierają się na \textbf{mikrousługach}. Mikrousługi wywodzą się z \textbf{SOA}. Termin SOA (ang. \textit{Service oriented architecture}) został pierwszy raz użyty przez analityka firmy Gartner podczas wykładu. Utworzył on ten termin, ponieważ zwrot ,,klient/serwer'' tracił na swoim pierwotnym znaczeniu, gdyż zamiast nazywać tak aplikację dla serwera lub klienta, ludzie zaczęli tak nazywać fizyczne maszyny. Następnie inni analitycy w 1996 r. publikowali na ten temat raporty. Bardziej znaczące użycie terminu SOA należało do Microsoftu. W 2000 r. opisywał zbiór standardów do komunikacji komputerów przez Internet, gdzie przedstawił architekturę SOA jako ważną, choć nie niezbędną, dla Web Services. Wkrótce termin podchwyciły inne firmy, w tym  takie jak IBM, Oracle, HP, publikując nowe koncepcje czy narzędzia powiązane z SOA. \cite{soaOreily}

SOA to po polsku architektura zorientowana na usługi. Polega na podzieleniu systemu informatycznego na odrębne części, które mogą znajdować się na różnych maszynach i komunikować się ze sobą przez sieć. Główne koncepcje SOA to: 
\begin{itemize}
\item usługi -- rozumiane jako samodzielne komponenty realizujące daną funkcjonalność biznesową,
\item wysoka interoperacyjność -- łatwe łączenie ze sobą systemów różnych typów,
\item luźne wiązania -- jak najmniejsza liczba zależności. \cite{soaOreily}
\end{itemize}

SOA to bardzo ogólne pojęcie, nie definiuje jakiej wielkości powinny być poszczególne usługi. Wraz z rozwojem technologii chmurowych, nastała potrzeba dostosowania paradygmatu SOA do wyzwań związanych ze skalowalnością, szybkością wytwarzania oprogramowania oraz potrzebą adaptacji nowych technologii dla istniejących rozbudowanych systemów. Odpowiedzią na ten problem okazały się mikrousługi (ang. \textit{microservices}).

\textbf{Mikrousługi} stanowią szczególny przypadek SOA. Ich główna cecha: mają być małe. Zamiast tworzyć jedną aplikację, która robi wszystko, system ma składać się z wielu małych, niezależnych od siebie komponentów, odpowiedzialnych za tylko jedną rzecz.

Z jednej strony powinny grupować powiązane ze sobą funkcjonalności, z drugiej strony nie wolno doprowadzać do sytuacji, gdy serwis może stać się zbyt duży i trudny w utrzymaniu. Pomocne w wyobrażeniu jakiej wielkości powinna być przeciętna mikrousługa są następujące wskazówki:
\begin{itemize}
\item Zasada pojedynczej odpowiedzialności, wywodząca się z zasad SOLID, a zaadoptowana do usług. Polega na umieszczaniu razem elementów, które będą zmieniać się z tego samego powodu. \cite{microservicesWmii}
\item Kod mikrousługi powinien być na tyle mały, żeby dało się go przepisać w dwa tygodnie. \cite{microservicesWmii}
\item Mikrousługa powinna być na tyle mała, żeby do pracy z nią wystarczył jeden zespół programistów. \cite{microservicesMaddie}
\item W przypadku gdy mikrousługa jest często używana i potrzebuje do działania wielu instancji, nie powinna jednocześnie powielać funkcjonalności rzadziej używanych i tym sposobem marnować zasobów. \cite{microservicesMaddie}
\end{itemize}

W odniesieniu do chmur, mikrousługi wprowadzają następujące udogodnienia:
%\begin{itemize}
%
%\end{itemize}





% 12 factor apps
% mikroserwisy
% nanoserwisy
% zero-downtime deplojment
% moze costam jeszcze.. NOSQL




%\subsection*{Współczesne wyzwania dla chmur obliczeniowych}





\section{Wymagania stawiane współczesnym chmurom}




\section{Dokąd zmierza rozwój CC.}


\chapter{Porównanie różnych podejść}



\section{Chmury publiczne}

\section{Chmury prywatne}


\chapter{Analiza wyboru platformy dla aplikacji mobilnej}

\section{Wytumaczenie czemu to jest typowy projekt}

\section{Wymagania co trzeba wziąć pod uwagę}

\section{Werdykt, kandydatka nr 1, 2 ,3}



\chapter{Opis wdrożenia aplikacji zgodnie z kandydatką nr 1 }
 
\chapter*{Podsumowanie}
 
 
 
 
\addcontentsline{toc}{chapter}{Spis rysunków}
\listoffigures

\addcontentsline{toc}{chapter}{Spis tabel}
\listoftables



\selectlanguage{polish}
\printbibliography
 


\end{document}
